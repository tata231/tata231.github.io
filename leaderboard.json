{
    "config": {
        "allow_multiple_models": true,
        "allow_orphans": true,
        "count_failed_submissions": true,
        "evaluate": {
            "command": "python evaluate.py predictions.json data.json out.json",
            "dependencies": [
                {
                    "child_path": "evaluate.py",
                    "parent_path": "",
                    "parent_uuid": "0xd8d30a3cd83e46e38d531aa5f1a98a9c"
                },
                {
                    "child_path": "data.json",
                    "parent_path": "",
                    "parent_uuid": "0xaec591480f514da58241c80b342fa727"
                },
                {
                    "child_path": "predictions.json",
                    "parent_path": "",
                    "parent_uuid": "{predict}"
                }
            ],
            "metadata": {
                "request_docker_image": "codalab/ubuntu:1.9"
            },
            "tag": "competition-evaluate"
        },
        "host": "https://worksheets.codalab.org",
        "log_worksheet_uuid": "0xa8f67766fbe245cf976fe707555d75a2",
        "make_predictions_public": false,
        "max_leaderboard_size": 10000,
        "max_submissions_per_period": 5,
        "max_submissions_total": 20,
        "metadata": {
            "name": "Hucvl-Recipe Challenge"
        },
        "predict": {
            "depth": 10,
            "metadata": {},
            "mimic": [
                {
                    "new": "0xaec591480f514da58241c80b342fa727",
                    "old": "0xfb5b18f8669a459195baa44a356038ef"
                }
            ],
            "tag": "competition-predict"
        },
        "quota_period_seconds": 86400,
        "refresh_period_seconds": 60,
        "score_specs": [
            {
                "key": "/out.json:textual_cloze",
                "name": "textual_cloze"
            },
            {
                "key": "/out.json:visual_cloze",
                "name": "visual_cloze"
            },
            {
                "key": "/out.json:visual_coherence",
                "name": "visual_coherence"
            },
            {
                "key": "/out.json:visual_ordering",
                "name": "visual_ordering"
            },
            {
                "key": "/out.json:guess_the_recipe",
                "name": "guess_the_recipe"
            }
        ],
        "submission_tag": "bela"
    },
    "leaderboard": [
        {
            "bundle": {
                "args": "run evaluate.py:0xd8d30a3cd83e46e38d531aa5f1a98a9c data.json:0xaec591480f514da58241c80b342fa727 predictions.json:0xdb6bc109cb734839b48644ef987f3144 \"python evaluate.py predictions.json data.json out.json\" --request-cpus 1 --request-time 1d --request-memory 2g --request-docker-image codalab/ubuntu:1.9 --request-disk 4g",
                "bundle_type": "run",
                "command": "python evaluate.py predictions.json data.json out.json",
                "data_hash": "0xdb8fd3623ef73f20c3711a4a2325d175f4127f0c",
                "dependencies": [
                    {
                        "child_path": "evaluate.py",
                        "child_uuid": "0x00189383ee1e4481b844b6d5b9124525",
                        "parent_name": "evaluate.py",
                        "parent_path": "",
                        "parent_uuid": "0xd8d30a3cd83e46e38d531aa5f1a98a9c"
                    },
                    {
                        "child_path": "data.json",
                        "child_uuid": "0x00189383ee1e4481b844b6d5b9124525",
                        "parent_name": "recipeqa45k_test_hash.json",
                        "parent_path": "",
                        "parent_uuid": "0xaec591480f514da58241c80b342fa727"
                    },
                    {
                        "child_path": "predictions.json",
                        "child_uuid": "0x00189383ee1e4481b844b6d5b9124525",
                        "parent_name": "tahasevim-pred-predict",
                        "parent_path": "",
                        "parent_uuid": "0xdb6bc109cb734839b48644ef987f3144"
                    }
                ],
                "id": "0x00189383ee1e4481b844b6d5b9124525",
                "is_anonymous": false,
                "metadata": {
                    "actions": [],
                    "allow_failed_dependencies": false,
                    "created": 1534431338,
                    "data_size": 4274,
                    "description": "{\"submit_id\": \"0x42f069410bd249cbb1eaa08f3c751b67\", \"predict_id\": \"0xdb6bc109cb734839b48644ef987f3144\", \"submitter_id\": \"0x47826d7982a4467da125bd36758f320c\"}",
                    "docker_image": "codalab/ubuntu@sha256:a8369aaa7afdb4d242104d85aa660c034a7bf89e438963bf73ba197fe3731be0",
                    "exitcode": 0,
                    "last_updated": 1534435562,
                    "name": "tahasevim-pred-results",
                    "remote": "vm-clws-prod-worker-1",
                    "request_cpus": 1,
                    "request_disk": "4g",
                    "request_docker_image": "codalab/ubuntu:1.9",
                    "request_gpus": 0,
                    "request_memory": "2g",
                    "request_network": false,
                    "request_priority": 0,
                    "request_queue": "",
                    "request_time": "1d",
                    "run_status": "Upload started",
                    "started": 1534435532,
                    "tags": [
                        "competition-evaluate"
                    ],
                    "time": 15.9086949825
                },
                "owner": {
                    "id": "0x47826d7982a4467da125bd36758f320c",
                    "type": "users"
                },
                "permission": 2,
                "permission_spec": "all",
                "state": "ready",
                "uuid": "0x00189383ee1e4481b844b6d5b9124525"
            },
            "scores": {
                "guess_the_recipe": 0,
                "textual_cloze": 0.26895119418483904,
                "visual_cloze": 0.27358490566037735,
                "visual_coherence": 0.6580493537015276,
                "visual_ordering": 0.40552486187845305
            },
            "submission": {
                "created": 1534421524,
                "description": "",
                "num_period_submissions": 1,
                "num_total_submissions": 1,
                "public": false,
                "user_name": "tahasevim"
            }
        }
    ],
    "updated": 1534436185.817254
}